---
title: "Verificação da disponibilidade dos dados para as EMAs na região sul do Brasil"
output: html_notebook
---

# Pré-configurações

```{r}
# Limpando área
rm(list = ls())

# Carregando pacotes necessários
easypackages::libraries(c("dplyr", "tidyverse", "ggfortify", "lubridate", "modelr"))

# Carregando scripts necessários
source("../R/network-dists.R")
source("../R/crv_detect.R")
source("../R/utils.R")

```

# Dados

Dados das EMAs

```{r}
var_data <- rio::import("../output/s08_data_sel.rds") %>% as_tibble
var_data
```

Metadados das EMAs

```{r}
var_info <- rio::import("../output/summary_80.rds") %>% as_tibble
var_info
```

# Constantes usadas ao longo das equações

```{r}
VAR <- "tavg" # Variável a ser testada
#TIME_INTERVAL <- 30 # Intervalo de dias testado
TIME_INTERVAL <- 60 # Intervalo de dias testado
#TIME_INTERVAL <- 90 # Intervalo de dias testado
M <- 10 # Número original de EMAs
PERC_REF <- 50 # porcentagem de dados válidos aceita dentro do período aplicado o método (maior ou igual)
TEXT_FALSE <- "Teste não aplicado, devido ao fato da EMA alvo não possuir dados válidos para comparar com os dados das EMAs vizinhas."

#REF <- "A803" # EMA de referência #teste
R2_THRESHOLD <- 0.55 # limiar do coeficiente de determinação (variância mínima explicada pela EMA vizinha em relação a EMA alvo)
#f <- 3 # fator do intervalo de confiança
```

# Disponibilidade dos dados

Conversão para valores diários

```{r}
daily_data <-
  var_data %>%
  rename("var" = VAR) %>%
#  filter(site %in% dists_ema$aux) %>%
  select(site, date, var) %>%
  group_by(site, date = as.Date(date)) %>%
  summarise(var = round(mean(var, na.rm = TRUE), 2)) %>%
  ungroup() %>%
  mutate(var = ifelse(test = is.nan(var), yes = NA, no = var))
daily_data

#daily_data %>% filter(site == "A802") 
```

Determinando a disponibilidade dos dados dentro do intervalo proposto

```{r}
# Número de dias de cada EMA
n_days_emas <-
  daily_data %>%
  group_by(site) %>%
  summarise(n_days = n()) #3288

# Gerando um identificador para aplicar a função group_by()
int <-
  rep(
    x = 1:(trunc(unique(n_days_emas$n_days) / TIME_INTERVAL) + 1),
    each = TIME_INTERVAL
    ) %>%
  # Foi gerada uma sequência de 1 até o número de divisões do TIME_INTERVAL, porém os ultimos n valores dos ids fizeram com que o tamanho dos ids ficassem maiores (3300, para TIME_INTERVAL = 60) do que o tamanho real da quantidade de dados (3288), então, usá-se o comando head() para 'cortar' fora os ids extras (12, para TIME_INTERVAL = 60)
  head(., n = unique(n_days_emas$n_days))

# Determinando a data onde começa e termina cada identificador
start_pos <- list()
end_pos <- list()

for (i in unique(int)) {
  start_pos[[i]] <- min(which(int == unique(int)[i]))
  end_pos[[i]] <- max(which(int == unique(int)[i]))
  }

start_pos <- unlist(start_pos)
end_pos <- unlist(end_pos)

date_int <-
  daily_data %>%
  filter(site == daily_data$site[1]) %>%
  select(date)
date_int <- date_int$date

start_int <- date_int[start_pos]
end_int <- date_int[end_pos]

# Determinando a disponibilidade de dados dentro de cada intervalo de n dias
disp_int <- 
  # Adicionando o intentificador à tabela de dados
  daily_data %>%
  group_by(site) %>% 
  mutate(int) %>%
  ungroup() %>%
  # Verificando a disponibilidade no intervalo proposto
  group_by(site, int) %>%
  summarise(
    tot_days = n(),
    tot_valid = sum(!is.na(var)),
    perc_valid = (tot_valid/tot_days) * 100) %>%
  # Adicionando a data em que começa e termina cada identificador
  mutate(start_int, end_int) %>%
  ungroup() %>%
  select(site, int, start_int, end_int, everything())
disp_int

# Nota 1: a variável 'int' na tabela de 'disp_int' corresponde ao número do intervalo analizado, por exemplo, para um intervalo de 60 em 60 dias (TIME_INTERVAL = 60), int = 1 corresponde aos primeiros 60 dias testados, int = 2, aos 60 dias seguintes, e assim sucessivamente.
```

Determinando a disponibilidade por intervalo, e verificando através da média qual intervalo de 60 dias teve maior disponibilidade dentro do período de 2008 à 2016

```{r}
int_list <- list()
info_int_list <- list()

for (i in seq(1:max(disp_int$int))) {
  int_list[[i]] <-
    disp_int %>%
    filter(int == seq(1:max(disp_int$int))[i]) %>%
    arrange(desc(perc_valid), site) }

for (i in seq_along(int_list)) {
  info_int_list[[i]] <-
    int_list[[i]] %>% 
    summarise(
      int = unique(int),
      n_emas = n(),
      start_int = unique(start_int),
      end_int = unique(end_int),
      size_int = (end_int - start_int) + 1,
#      days = unique(tot_days),
      perc_min = min(perc_valid),
      perc_mean = mean(perc_valid),
      perc_max = max(perc_valid)) }

info_int <- bind_rows(info_int_list)
info_int

#info_int %>% filter(perc_mean == min(info_int$perc_mean))
#sum(info_int$days) #~ 9 anos
```

Intervalo com maior porcentagem (min) de dados válidos

```{r}
int_min <- info_int %>% filter(perc_min == max(info_int$perc_min))
int_min

# Nota 2a: (int = 36, para TIME_INTERVAL = 60)
# Nota 2b: (int = 24, para TIME_INTERVAL = 90)
```

Intervalo com maior porcentagem (mean) de dados válidos

```{r}
int_mean <- info_int %>% filter(perc_mean == max(info_int$perc_mean))
int_mean

# Nota 3a: (int = 36, para TIME_INTERVAL = 60)
# Nota 3b: (int = 21, para TIME_INTERVAL = 90)
```

# Gráficos e Mapas

Variação temporal da disponibilidade de cada intervalo de tempo para cada EMA

```{r, fig.width=9.3, fig.height=7.25, fig.align='center'}
sites_ord <-
  # Gerando vetor que será usado para ordenar a variável 'site'
  unique(disp_int$site)

disp_int_plot <-
  disp_int %>%
  mutate(
    # Substituindo valores de porcentagem iguais à 0 por NA
    perc_valid_na = ifelse(perc_valid > 0, perc_valid, NA),
    # Ordenando a variável 'site'
    site = ordered(site, levels = sites_ord) )

g1 <-
  ggplot(aes(x = start_int, y = site), data = disp_int_plot) +
  geom_point(aes(colour = perc_valid_na), shape = 15, size = 2.5) + 
  labs(x = "Tempo (em anos)", y = "Estações Meteorológicas Automáticas") +
  scale_colour_gradientn(
    paste0("Time Interval =  ", TIME_INTERVAL, " days\n(%)"),
    colours = viridis::viridis(n = 256), na.value = NA) +
  # scale_x_datetime(
  #   date_breaks = "12 months", 
  #   date_labels = "%Y") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 0, hjust = 1)) +
#  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(text = element_text(size = 10)) # +
  # ggplot2::ggtitle(TITLE) +
  # ggplot2::theme(plot.title = element_text(hjust = 0.5))
g1

```

Variação dos valores mínimos, médios e máximos para cada intentificador

```{r, fig.width=9.3, fig.height=7.25, fig.align='center'}
lvector_x <- 
  c(
    min(lubridate::year(info_int$start_int)),
    max(lubridate::year(info_int$start_int)) )
bvector_x <-
  seq(
    from = lvector_x[1],
    to = lvector_x[2],
    by = 1 )

lvector_y <- c(0,100)
bvector_y <-
  seq(
    from = lvector_y[1],
    to = lvector_y[2],
    by = 10 )

g2 <-
  ggplot(info_int, aes(start_int)) +
  # scale_x_continuous(breaks = bvector_x, limits = lvector_x) +
  scale_y_continuous(breaks = bvector_y, limits = lvector_y) +
  geom_line(aes(y = perc_max, colour = "Max")) +
  geom_line(aes(y = perc_mean, colour = "Mean")) + 
  geom_line(aes(y = perc_min, colour = "Min")) + 
  labs(x = "Tempo (em anos)", y = "Disponibilidade (%)", color = "\n")
g2

```
# Seleção do período para a aplicação do teste

Para testar o QC espacial selecionaremos o período de maior disponibilidade de dados entre a rede de EMAS. Como a janela de aplicação do método é de 60 dias, determinaremos o maior período consecutivo de janela de 60 dias com disponibilidade acima de 95%.


```{r}
# Valor de porcentagem que será usada como limiar para filtragem
perc_lim <- 95

# Gerando nova coluna com valores de 0 e 1 usando como parâmetro o valor escolhido anteriormente
sel_info_int <-
  info_int %>%
  mutate(
    id =
      if_else(
        condition = (perc_mean >= perc_lim),
        true = 1,
        false = 0) )

# Função usada para verificar o começo e o fim de cada sequência de 1, e o tamanho delas
sted.seq <- function(SEQ_01) {
  pre_seq <- diff(c(999, SEQ_01))
  pos_seq <- diff(c(SEQ_01, 999))
  # para remover o índice '999' inicial em caso de sequência '1 1 ...' inicial
  pre_seq[1] <-
    ifelse(
      test = (abs(pre_seq[1]) == 998),
      yes = 1,
      no = 0)
  # para remover o índice '999' final em caso de sequência '... 1 1' final
  pos_seq[length(pos_seq)] <-
    ifelse(
      test = (abs(pos_seq[length(pos_seq)]) == 998),
      yes = -1,
      no = 0)
  start_seq <- which(pre_seq == 1)
  end_seq <- which(pos_seq == -1)
  size_seq <- (end_seq - start_seq) + 1
  s <- data.frame(start_seq, end_seq, size_seq)
  return(s) }

# Selecionando a maior sequência de disponibilidades com valor igual ou acima do limiar escolhido
sted_seq <-
  sted.seq(SEQ_01 = sel_info_int$id) %>%
  arrange(desc(size_seq))
pos_longer_disp <-
  seq(
    from = ((sted_seq[1,])$start_seq),
    to = ((sted_seq[1,])$end_seq) )
period_longer_disp <-
  info_int %>%
  filter(int %in% pos_longer_disp)
period_longer_disp

# Começo do período onde a média da disponibilidade dos intervalos de N dias apresentou maiores valores
start_period <- period_longer_disp$start_int[1]

# Fim do período onde a média da disponibilidade dos intervalos de N dias apresentou maiores valores
end_period <- period_longer_disp$end_int[length(period_longer_disp$end_int)]

# crv_detect(
#   x = sel_info_int$id,
#   thresh = -999,
#   min.steps = 1)
```

# Seleção de dados da EMA selecionada e suas vizinhas

Cálculo de distâncias

```{r}
dists <-
  network_dists(
    netw_ref = var_info,
    netw_aux = var_info,
    dx_max = NA,
    lon_lat = TRUE)
dists
```

Gerando uma lista com cada ema de referência e suas M vizinhas mais próximas

```{r}
neighbors_list <- list()

for (i in seq_along(unique(dists$ref))) {
  neighbors_list[[i]] <-
    dists %>%
    filter(ref == unique(dists$ref)[i]) %>%
    arrange(dis) %>%
    head(M + 1)
  }

# head(neighbors_list)
# tail(neighbors_list)

```

<!-- Dados estruturados com formato sililar ao do exemplo de aplicação do método. O formato dos dados é com a data na 1ª coluna, a EMA de referência na 2ª coluna e as EMAs vizinhas nas demais colunas. -->

Variável com os dados diários estruturados no formato wide, e com o período selecionado

```{r}
daily_data_wide <-
  daily_data %>%
  spread(site, var) %>%
#  rename("x" = REF) %>%
  as.tibble() %>%
  filter(date %in% seq.Date(from = start_period, to = end_period, by = 1))
daily_data_wide
```

Gerando uma lista a partir dos dados diários no formato wide, com cada EMA e suas vizinhas, e separados por intervalo de N dias

```{r}
daily_data_wide_list <- list()
daily_data_wide_list_int <- list()

for (e in seq_along(neighbors_list)) {
  for (i in seq_along(period_longer_disp$int)) {
    daily_data_wide_list_int[[i]] <-
      daily_data_wide %>%
      mutate(ema_id = ((neighbors_list[[e]])$aux)[1]) %>%
      select(date, ema_id, (neighbors_list[[e]])$aux) %>%
      rename("x" = (((neighbors_list[[e]])$aux)[1])) %>%
      mutate(
        int_id = rep(
          x = period_longer_disp$int,
          period_longer_disp$size_int)) %>%
      select(ema_id, int_id, everything()) %>% # ordem das colunas
      filter(int_id == (period_longer_disp$int)[i])
    names(daily_data_wide_list_int)[i] <-
      paste0('int_', unique(daily_data_wide_list_int[[i]]$int_id))
    }
  daily_data_wide_list[[e]] <- daily_data_wide_list_int
  names(daily_data_wide_list)[e] <-
    paste0('ema_', unique(daily_data_wide_list_int[[1]]$ema_id))
  }

# View(daily_data_wide_list)

daily_data_wide_list$ema_A801$int_27
```

# Aplicação do teste

Modelo de regressão

```{r}
reg_model <- function(df) {lm(x ~ y, data = df, na.action = na.exclude)}
```

Aplicando a regressão entre a EMA de referência e cada EMA vizinha

```{r}
# e = 2; i = 1
# Caso: Ideal.
# EMA Alvo: Apresenta porcentagem de dados válidos diferente de zero.
# EMAs Vizinhas: Todas apresentam porcentagem de dados válidos diferente de zero.
# Aplicação: Neste caso, todas as EMAs são utilizadas.

# e = 1 ; i = 1
# Caso: Não ideal, e corrigível.
# EMA Alvo: Apresenta porcentagem de dados válidos diferente de zero.
# EMAs Vizinhas: Nem todas apresentam porcentagem de dados válidos diferente de zero.
# Aplicação: Neste caso, as EMAs vizinhas que apresentaram porcentagem nula são removidas.

# e = 78; i = 1
# Caso: Não ideal, e não corrigível.
# EMA Alvo: Não apresenta porcentagem de dados válidos diferente de zero.
# EMAs Vizinhas: A porcentagem de dados torna-se irrelevante (podendo ser nula ou não), uma vez que não existem dados na EMA alvo para comparação.
# Aplicação: Neste caso, o teste não é aplicável para a EMA alvo neste intervalo.

# Nota 4: na EMA A882 (e = 78), até o intervalo i = 3, somente existem valores NAs, expandindo para o intervalo i = 4, resulta que até os primeiros 182 dias, somente possuí valores NAs.
```

```{r}
tab_by_station_list <- list()
tab_by_station_list_int <- list()

for (e in seq_along(daily_data_wide_list)) {
  for (i in seq_along(daily_data_wide_list[[1]])) {
    # Verificando a disponibilidade da EMA alvo e suas vizinhas no intervalo i
    xyn_disp <-
      daily_data_wide_list[[e]][[i]] %>%
      select(-c("ema_id", "int_id", "date")) %>%
      gather(., key = 'yn', value = 'var') %>%
      group_by(yn) %>%
      summarise(
        tot = n(),
        valid = sum(!is.na(var)),
        perc_valid = (valid/tot) * 100 ) %>%
      mutate(
        ema_id = unique((daily_data_wide_list[[e]][[i]] %>% select(ema_id))[[1]]),
        int_id = unique((daily_data_wide_list[[e]][[i]] %>% select(int_id))[[1]]),
        status = ifelse(test = (yn == "x"), yes = "target", no = "neighbor")
        ) %>%
      select(ema_id, int_id, status, everything()) %>%
      arrange(desc(status), desc(perc_valid))
    # Verificando se a EMA alvo possuí porcentagem diferente de zero
    x_filter <- 
      xyn_disp %>%
      filter(status == "target") %>%
      summarise(have_valid = (valid != 0)) %>%
      ungroup()
    # Verificando se alguma EMA vizinha possui disponibilidade abaixo do percentual de referência
    yn_filter <-
      xyn_disp %>%
      filter(status == "neighbor") %>%
      filter(perc_valid < PERC_REF) %>%
      select(yn) %>%
      ungroup()
    if (x_filter$have_valid == TRUE) {
      tab_by_station_list_int[[i]] <-
        daily_data_wide_list[[e]][[i]] %>%
        select(-c(yn_filter[[1]])) %>%
        gather(id, y, -c(x, date, ema_id, int_id)) %>%
        group_by(id) %>%
        nest() %>%
        mutate(
          model = map(data, reg_model),
          pred = map2(data, model, add_predictions),  # x'
          resid = map2(data, model, add_residuals) )   # x - x'
      names(tab_by_station_list_int)[i] <-
        paste0('int_', unique((tab_by_station_list_int[[i]]$data)[[1]][[2]]))
      }
    if (x_filter$have_valid == FALSE) {
      tab_by_station_list_int[[i]] <- TEXT_FALSE
      names(tab_by_station_list_int)[i] <-
        paste0('int_', unique(xyn_disp$int_id))
      }
    }
  tab_by_station_list[[e]] <- tab_by_station_list_int
  names(tab_by_station_list)[e] <-
    paste0('ema_', unique((daily_data_wide_list[[e]][[1]])$ema_id))
  }

# View(tab_by_station_list)

tab_by_station_list$ema_A801$int_27


# Nota 5: Como a lista é extensa, será mostrado apenas o primeiro item dela, no caso, o intervalo 27, da EMA A801. Para maiores informações, verificar o "View()".
```

Verificando se existem intervalos que não possuem dados válidos na EMA alvo

```{r}
have_valid_data_list <- list()
have_valid_data_list_int <- list()
no_have_valid_data_list <- list()
no_have_valid_data_list_int <- list()
length_list <- list()

# Gerando lista de TRUE e FALSE que será usada como referência nas demais aplicações
for (e in seq_along(tab_by_station_list)) {
  for (i in seq_along(tab_by_station_list[[1]])) {
    have_valid_data_list_int[[i]] <- !is.character(tab_by_station_list[[e]][[i]])
    names(have_valid_data_list_int)[i] <- names(tab_by_station_list[[e]])[i]
    }
  have_valid_data_list[[e]] <- have_valid_data_list_int
  names(have_valid_data_list)[e] <- names(tab_by_station_list)[e]
  }

# Verificando quais intervalos de cada EMAs não possuem dados
for (e in seq_along(have_valid_data_list)) {
  no_have_valid_data_list_int[[e]] <- names(which(!unlist(have_valid_data_list[[e]])))
  names(no_have_valid_data_list_int)[e] <- names(have_valid_data_list)[e]
  length_list[e] <- length(no_have_valid_data_list_int[[e]]) != 0
  }
no_have_valid_data_list <- no_have_valid_data_list_int[unlist(length_list)]
no_have_valid_data_list

# # Script que será usado como base nas próximas aplicações (NÃO EXECUTÁVEL)
# for (e in seq_along(have_valid_data_list)) {
#   for (i in seq_along(have_valid_data_list[[1]])) {
#     if (have_valid_data_list[[e]][[i]] == TRUE) {
#       *NOMEDALISTA*_list_int[[i]] <- *EQUACOES*
#       }
#     if (have_valid_data_list[[e]][[i]] == FALSE) {
#       *NOMEDALISTA*_list_int[[i]] <- TEXT_FALSE
#       }
#     names(*NOMEDALISTA*_list_int)[i] <- names(have_valid_data_list[[e]])[i]
#     }
#   *NOMEDALISTA*_list[[e]] <- *NOMEDALISTA*_list_int
#   names(*NOMEDALISTA*_list)[e] <- names(have_valid_data_list)[e]
#   }
# 
# View(*NOMEDALISTA*_list)
```

Valores previstos ou estimados de temperatura das EMAs vizinhas via regressão linear simples.

```{r}
tab_previstos_list <- list()
tab_previstos_list_int <- list()

for (e in seq_along(have_valid_data_list)) {
  for (i in seq_along(have_valid_data_list[[1]])) {
    if (have_valid_data_list[[e]][[i]] == TRUE) {
      tab_previstos_list_int[[i]] <- unnest(tab_by_station_list[[e]][[i]], pred)
      }
    if (have_valid_data_list[[e]][[i]] == FALSE) {
      tab_previstos_list_int[[i]] <- TEXT_FALSE
      }
    names(tab_previstos_list_int)[i] <- names(have_valid_data_list[[e]])[i]
    }
  tab_previstos_list[[e]] <- tab_previstos_list_int
  names(tab_previstos_list)[e] <- names(have_valid_data_list)[e]
  }

# View(tab_previstos_list)

tab_previstos_list$ema_A801$int_27
```

Tabela anterior em formato wide para visualização similar a do artigo de referência do SRT.

```{r}
tab_previstos_wide_list <- list()
tab_previstos_wide_list_int <- list()

for (e in seq_along(have_valid_data_list)) {
  for (i in seq_along(have_valid_data_list[[1]])) {
    if (have_valid_data_list[[e]][[i]] == TRUE) {
      tab_previstos_wide_list_int[[i]] <-
        tab_previstos_list[[e]][[i]] %>%
        select(date, id, pred) %>%
    #    mutate(id = as.numeric(as.factor(id))) %>%
        spread(id, pred) %>%
        setNames(c("date", paste0("xlin", names(.)[-1])))
      }
    if (have_valid_data_list[[e]][[i]] == FALSE) {
      tab_previstos_wide_list_int[[i]] <- TEXT_FALSE
      }
    names(tab_previstos_wide_list_int)[i] <- names(have_valid_data_list[[e]])[i]
    }
  tab_previstos_wide_list[[e]] <- tab_previstos_wide_list_int
  names(tab_previstos_wide_list)[e] <- names(have_valid_data_list)[e]
  }

# View(tab_previstos_wide_list)

tab_previstos_wide_list$ema_A801$int_27
```

Qualidade do ajuste das regressões.

```{r}
# e = 2; i = 1
# e = 1 ; i = 1
# e = 78; i = 1
# rm(e, i)

tab_glance_list <- list()
tab_glance_list_int <- list()
tab_glance_sel_list <- list()
tab_glance_sel_list_int <- list()
# N_list <- list() # Não será rodado pois abaixo o mesmo é gerado com outro nome
# N_list_int <- list()

for (e in seq_along(have_valid_data_list)) {
  for (i in seq_along(have_valid_data_list[[1]])) {
    if (have_valid_data_list[[e]][[i]] == TRUE) {
      tab_glance_list_int[[i]] <-
        tab_by_station_list[[e]][[i]] %>%
        mutate(glance = map(model, broom::glance)) %>% 
        unnest(glance, .drop = TRUE) %>%
        arrange(sigma)
      tab_glance_sel_list_int[[i]] <-
        tab_glance_list_int[[i]] %>%
        filter(adj.r.squared > R2_THRESHOLD)
#      N_list_int[[i]] <- nrow(tab_glance_sel_list_int[[i]])
      }
    if (have_valid_data_list[[e]][[i]] == FALSE) {
      tab_glance_list_int[[i]] <- TEXT_FALSE
      tab_glance_sel_list_int[[i]] <- TEXT_FALSE
#      N_list_int[[i]] <- TEXT_FALSE
      }
    names(tab_glance_list_int)[i] <- names(have_valid_data_list[[e]])[i]
    names(tab_glance_sel_list_int)[i] <- names(have_valid_data_list[[e]])[i]
#    names(N_list_int)[i] <- names(have_valid_data_list[[e]])[i]
    }
  tab_glance_list[[e]] <- tab_glance_list_int
  tab_glance_sel_list[[e]] <- tab_glance_sel_list_int
#  N_list[[e]] <- N_list_int
  names(tab_glance_list)[e] <- names(have_valid_data_list)[e]
  names(tab_glance_sel_list)[e] <- names(have_valid_data_list)[e]
#  names(N_list)[e] <- names(have_valid_data_list)[e]
  }

# View(tab_glance_list)
# View(tab_glance_sel_list)
# View(N_list)

tab_glance_list$ema_A801$int_27
tab_glance_sel_list$ema_A801$int_27
# N_list$ema_A801$int_27
```

Relação entre o $\sigma$ das estimativas e o coeficiente $R^2$.

```{r}
plot_list <- list()
plot_list_int <- list()

for (e in seq_along(have_valid_data_list)) {
  for (i in seq_along(have_valid_data_list[[1]])) {
    if (have_valid_data_list[[e]][[i]] == TRUE) {
      plot_list_int[[i]] <-
        tab_glance_sel_list[[e]][[i]] %>%
        ggplot(aes(x = adj.r.squared, y = sigma)) +
        geom_point() + 
        geom_smooth(method = "lm") +
        labs(x = expression(R^2), y = expression(sigma~~(degree~C))) +
        theme_bw()
      }
    if (have_valid_data_list[[e]][[i]] == FALSE) {
      plot_list_int[[i]] <- TEXT_FALSE
      }
    names(plot_list_int)[i] <- names(have_valid_data_list[[e]])[i]
    }
  plot_list[[e]] <- plot_list_int
  names(plot_list)[e] <- names(have_valid_data_list)[e]
  }

# View(plot_list)

plot_list$ema_A801$int_27
```

Termos necessários para equação 5 de Hubbard et al. 2012.

```{r}
inv_sum_si2_list <- list()
inv_sum_si2_list_int <- list()
tab_N_list <- list()
tab_N_list_int <- list()
slin_list <- list()
slin_list_int <- list()

for (e in seq_along(have_valid_data_list)) {
  for (i in seq_along(have_valid_data_list[[1]])) {
    if (have_valid_data_list[[e]][[i]] == TRUE) {
      # lado direito da eq. 5
      inv_sum_si2_list_int[[i]] <- sum(1/((tab_glance_sel_list[[e]][[i]])$sigma)^2)
      # num d estações vizinhas - numerador do lado esquerdo da eq. 5
      tab_N_list_int[[i]] <- length((tab_glance_sel_list[[e]][[i]])$sigma)
      # constante: s', linha 36, coluna 13, da tab2, obtida isolando s' na eq. 5
      slin_list_int[[i]] <- sqrt((tab_N_list_int[[i]])/(inv_sum_si2_list_int[[i]]))
      }
    if (have_valid_data_list[[e]][[i]] == FALSE) {
      inv_sum_si2_list_int[[i]] <- TEXT_FALSE
      tab_N_list_int[[i]] <- TEXT_FALSE
      slin_list_int[[i]] <- TEXT_FALSE
      }
    names(inv_sum_si2_list_int)[i] <- names(have_valid_data_list[[e]])[i]
    names(tab_N_list_int)[i] <- names(have_valid_data_list[[e]])[i]
    names(slin_list_int)[i] <- names(have_valid_data_list[[e]])[i]
    }
  inv_sum_si2_list[[e]] <- inv_sum_si2_list_int
  tab_N_list[[e]] <- tab_N_list_int
  slin_list[[e]] <- slin_list_int
  names(inv_sum_si2_list)[e] <- names(have_valid_data_list)[e]
  names(tab_N_list)[e] <- names(have_valid_data_list)[e]
  names(slin_list)[e] <- names(have_valid_data_list)[e]
  }

# View(inv_sum_si2_list)
# View(tab_N_list)
# View(slin_list)

inv_sum_si2_list$ema_A801$int_27
tab_N_list$ema_A801$int_27
slin_list$ema_A801$int_27


# e = 1; i = 1
# e = 78; i = 1

# $ema_A847
# [1] "int_34"
# $ema_A882
# [1] "int_27" "int_28" "int_29"
# $ema_A883
# [1] "int_27" "int_28" "int_29" "int_30"

```

############################# CONTINUAR AQUI ###################################

Vamos filtrar os dados gerados anteriormente mantendo somente as EMAs selecionadas.

```{r}
daily_data_wide_sel_list <- list()
daily_data_wide_sel_list_int <- list()
tab_by_station_sel_list <- list()
tab_by_station_sel_list_int <- list()
tab_previstos_sel_list <- list()
tab_previstos_sel_list_int <- list()
tab_previstos_wide_sel_list <- list()
tab_previstos_wide_sel_list_int <- list()

for (e in seq_along(have_valid_data_list)) {
  for (i in seq_along(have_valid_data_list[[1]])) {
    if (have_valid_data_list[[e]][[i]] == TRUE) {
      daily_data_wide_sel_list_int[[i]] <-
        daily_data_wide_list[[e]][[i]] %>%
        select(c("date", "x", (tab_glance_sel_list[[e]][[i]])$id))
      tab_by_station_sel_list_int[[i]] <-
        tab_by_station_list[[e]][[i]] %>%
        filter(id %in% (tab_glance_sel_list[[e]][[i]])$id)
      tab_previstos_sel_list_int[[i]] <-
        tab_previstos_list[[e]][[i]] %>%
        filter(id %in% (tab_glance_sel_list[[e]][[i]])$id)
    #   tab_previstos_wide_sel_list_int[[i]] <-
    #     tab_previstos_sel_list[[e]][[i]] %>% 
    #     select(date, id, pred) %>% 
    # #    mutate(id = as.numeric(as.factor(id))) %>%
    #     spread(id, pred) %>%
    #     setNames(c("date", paste0("xlin_", names(.)[-1])))
      }
    if (have_valid_data_list[[e]][[i]] == FALSE) {
      daily_data_wide_sel_list_int[[i]] <- TEXT_FALSE
      tab_by_station_sel_list_int[[i]] <- TEXT_FALSE
      tab_previstos_sel_list_int[[i]] <- TEXT_FALSE
      # tab_previstos_wide_sel_list_int[[i]] <- TEXT_FALSE
      }
    names(daily_data_wide_sel_list_int)[i] <- names(have_valid_data_list[[e]])[i]
    names(tab_by_station_sel_list_int)[i] <- names(have_valid_data_list[[e]])[i]
    names(tab_previstos_sel_list_int)[i] <- names(have_valid_data_list[[e]])[i]
    # names(tab_previstos_wide_sel_list_int)[i] <- names(have_valid_data_list[[e]])[i]
    }
  daily_data_wide_sel_list[[e]] <- daily_data_wide_sel_list_int
  tab_by_station_sel_list[[e]] <- tab_by_station_sel_list_int
  tab_previstos_sel_list[[e]] <- tab_previstos_sel_list_int
  # tab_previstos_wide_sel_list[[e]] <- tab_previstos_wide_sel_list_int

  names(daily_data_wide_sel_list)[e] <- names(have_valid_data_list)[e]
  names(tab_by_station_sel_list)[e] <- names(have_valid_data_list)[e]
  names(tab_previstos_sel_list)[e] <- names(have_valid_data_list)[e]
  # names(tab_previstos_wide_sel_list)[e] <- names(have_valid_data_list)[e]
  }

tab_previstos_wide_sel_list <- list()
tab_previstos_wide_sel_list_int <- list()

e = 63; i = 5
 e = 64; i = 5
 e = 65; i = 5
e = 66; i = 5


for (e in seq_along(have_valid_data_list)) {
  for (i in seq_along(have_valid_data_list[[1]])) {
    if (have_valid_data_list[[e]][[i]] == TRUE) {
      tab_previstos_wide_sel_list_int[[i]] <-
        tab_previstos_sel_list[[e]][[i]] %>% 
        select(date, id, pred) %>% 
    #    mutate(id = as.numeric(as.factor(id))) %>%
        spread(id, pred) %>%
        setNames(c("date", paste0("xlin_", names(.)[-1])))
      }
    if (have_valid_data_list[[e]][[i]] == FALSE) {
      tab_previstos_wide_sel_list_int[[i]] <- TEXT_FALSE
      }
    names(tab_previstos_wide_sel_list_int)[i] <- names(have_valid_data_list[[e]])[i]
    }
  tab_previstos_wide_sel_list[[e]] <- tab_previstos_wide_sel_list_int
  names(tab_previstos_wide_sel_list)[e] <- names(have_valid_data_list)[e]
  }

tab_previstos_wide_sel_list

# View(daily_data_wide_sel_list)
# View(tab_by_station_sel_list)
# View(tab_previstos_sel_list)
# View(tab_previstos_wide_sel_list)

names(tab_previstos_sel_list)[65]


daily_data_wide_sel_list$ema_A801$int_27
tab_by_station_sel_list$ema_A801$int_27
tab_previstos_sel_list$ema_A801$int_27
tab_previstos_wide_sel_list$ema_A801$int_27

                                                          ### tab_previstos_sel_list$ema_A801$int_27$data[1:2] #VERIFICAR DEPOIS


daily_data_wide_sel_list[[e]][[i]]
tab_by_station_sel_list[[e]][[i]]
tab_previstos_sel_list[[e]][[i]]
tab_previstos_wide_sel_list[[e]][[i]]


```



```{r}
# data_wide_sel <-
#   data_wide %>%
#   select(c("date", "x", tab_glance_sel$id))
# data_wide_sel

# tab_by_station_sel <-
#   tab_by_station %>%
#   filter(id %in% tab_glance_sel$id)
# tab_by_station_sel

# tab_previstos_sel <-
#   tab_previstos %>%
#   filter(id %in% tab_glance_sel$id)
# tab_previstos_sel

tab_previstos_wide_sel <- 
  tab_previstos_sel %>% 
  select(date, id, pred) %>% 
  mutate(id = as.numeric(as.factor(id))) %>%
  spread(id, pred) %>%
  setNames(c("date", paste0("xlin", names(.)[-1])))
tab_previstos_wide_sel
```






